{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea5ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bad450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "from pprint import pprint as pp\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.pipeline import Pipeline \n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import homogeneity_score, silhouette_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import MiniBatchKMeans, DBSCAN\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8056199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 700)\n",
    "pd.set_option('display.max_rows', 400)\n",
    "pd.set_option('display.min_rows', 10)\n",
    "pd.set_option('display.expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Path.cwd() / 'Credit_card_data' \n",
    "\n",
    "cc1_file = data / 'creditcard_sampledata.csv'\n",
    "cc2_file = data / 'creditcard_sampledata_2.csv'\n",
    "cc3_file = data / 'creditcard_sampledata_3.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5855b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit card data reading\n",
    "df = pd.read_csv(cc3_file)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b28ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e89a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of fraud and no fraud and print them\n",
    "occ = df['Class'].value_counts()\n",
    "occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f10a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the ratio of fraud cases\n",
    "ratio_cases = occ/len(df.index)\n",
    "print(f'Ratio of fraudulent cases: {ratio_cases[1]}\\nRatio of non-fraudulent cases: {ratio_cases[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c230842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df: pd.DataFrame) -> (np.ndarray, np.ndarray):\n",
    "    \"\"\"\n",
    "    Convert the DataFrame into two variable\n",
    "    X: data columns (V1 - V28)\n",
    "    y: lable column\n",
    "    \"\"\"\n",
    "    X = df.iloc[:, 2:30].values\n",
    "    y = df.Class.values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158f3a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create a scatter plot of our data and labels\n",
    "def plot_data(X: np.ndarray, y: np.ndarray):\n",
    "    plt.scatter(X[y == 0, 0], X[y == 0, 1], label=\"Class #0\", alpha=0.5, linewidth=0.15)\n",
    "    plt.scatter(X[y == 1, 0], X[y == 1, 1], label=\"Class #1\", alpha=0.5, linewidth=0.15, c='r')\n",
    "    plt.legend()\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eedcb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y from the prep_data function \n",
    "X, y = prep_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot our data by running our plot data function on X and y\n",
    "plot_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ecab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.V2[df.Class == 0], df.V3[df.Class == 0], label=\"Class #0\", alpha=0.5, linewidth=0.15)\n",
    "plt.scatter(df.V2[df.Class == 1], df.V3[df.Class == 1], label=\"Class #1\", alpha=0.5, linewidth=0.15, c='r')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c124e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "method = RandomOverSampler()\n",
    "X_resampled, y_resampled =  method.fit_sample(X, y)\n",
    "\n",
    "compare_plots(X_resampled, y_resampled, X, y)\n",
    "# The darker blue points reflect there are more identical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c266437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define resampling method and split into train and test\n",
    "method = SMOTE(kind='borderline1')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n",
    "\n",
    "# Apply resampling to the training data only\n",
    "X_resampled, y_resampled = method.fit_sample(X_train, y_train)\n",
    "\n",
    "# Continue fitting the model and obtain predictions\n",
    "model = LogisticRegression()\n",
    "model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Get model performance metrics\n",
    "predicted = model.predict(X_test)\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the prep_data function\n",
    "X, y = prep_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d99a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X shape: {X.shape}\\ny shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5392d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling method\n",
    "method = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7384a40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the resampled feature set\n",
    "X_resampled, y_resampled = method.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the resampled data\n",
    "plot_data(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85b2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(pd.Series(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac0f3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(pd.Series(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a2816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_plot(X: np.ndarray, y: np.ndarray, X_resampled: np.ndarray, y_resampled: np.ndarray, method: str):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(X[y == 0, 0], X[y == 0, 1], label=\"Class #0\", alpha=0.5, linewidth=0.15)\n",
    "    plt.scatter(X[y == 1, 0], X[y == 1, 1], label=\"Class #1\", alpha=0.5, linewidth=0.15, c='r')\n",
    "    plt.title('Original Set')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(X_resampled[y_resampled == 0, 0], X_resampled[y_resampled == 0, 1], label=\"Class #0\", alpha=0.5, linewidth=0.15)\n",
    "    plt.scatter(X_resampled[y_resampled == 1, 0], X_resampled[y_resampled == 1, 1], label=\"Class #1\", alpha=0.5, linewidth=0.15, c='r')\n",
    "    plt.title(method)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1ec29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_plot(X, y, X_resampled, y_resampled, method='SMOTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e85f9",
   "metadata": {},
   "source": [
    "# Fraud detection algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8054e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: split the features and labels into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90477a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define which model to use\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdca736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fit the model to the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9059c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Obtain model predictions from the test data\n",
    "y_predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2446a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Compare y_test to predictions and obtain performance metrics (r^2 score)\n",
    "r2_score(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399f8bb0",
   "metadata": {},
   "source": [
    "# Exploring the traditional method of fraud detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75dde8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc4fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Class').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88f6f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['flag_as_fraud'] = np.where(np.logical_and(df.V1 < -3, df.V3 < -5), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b23b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.Class, df.flag_as_fraud, rownames=['Actual Fraud'], colnames=['Flagged Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd22474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48beef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a logistic regression model to our data\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65731dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain model predictions\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c6dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classifcation report and confusion matrix\n",
    "print('Classification report:\\n', classification_report(y_test, predicted))\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=predicted)\n",
    "print('Confusion matrix:\\n', conf_mat)\n",
    "\"\"\"\n",
    "these results are better than the rules based \n",
    "model. We are getting far fewer false positives, so that's an improvement.\n",
    "Also, we're catching a higher percentage of fraud cases, so that is also better than before. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03940d92",
   "metadata": {},
   "source": [
    "# Logistic regression with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca50d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which resampling method and which ML model to use in the pipeline\n",
    "# resampling = SMOTE(kind='borderline2')  # has been changed to BorderlineSMOTE\n",
    "resampling = BorderlineSMOTE()\n",
    "model = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a45c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('SMOTE', resampling), ('Logistic Regression', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a943fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that you have our pipeline defined, aka combining a logistic regression with a SMOTE method, let's run it on the data. You can treat the pipeline as if it were a single machine learning model.\n",
    "# Split your data X and y, into a training and a test set and fit the pipeline onto the training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "pipeline.fit(X_train, y_train) \n",
    "predicted = pipeline.predict(X_test)\n",
    "\n",
    "# Obtain the results from the classification report and confusion matrix \n",
    "print('Classifcation report:\\n', classification_report(y_test, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0826f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=predicted)\n",
    "print('Confusion matrix:\\n', conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2ba7eb",
   "metadata": {},
   "source": [
    "# Fraud detection using labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72492fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "print(f'Accuracy Score:\\n{accuracy_score(y_test, predicted)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TF2-py3)",
   "language": "python",
   "name": "tf2-py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
